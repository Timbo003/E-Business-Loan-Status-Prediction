---
title: "E-Business Loan Status Prediction"
output: 
  html_document:
    keep_md: true
---

# Load libraries

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(pROC)
library(class)
library(rpart)
```

------------------------------------------------------------------------

# Load the data

```{r}
rawData <- read_csv("loan_data.csv")

# print col names
names(rawData)
```

# Transform the data

```{r}
rawData <- rawData %>% select(-Loan_ID)

# Transform categorical variables to factors
rawData <- rawData %>% mutate(
  Married = factor(ifelse(Married == "Yes", TRUE, FALSE)),
  Education = factor(ifelse(Education == "Graduate", TRUE, FALSE)),
  Self_Employed = factor(ifelse(Self_Employed == "Yes", TRUE, FALSE)),
  Gender = factor(Gender),
  Dependents = factor(Dependents),
  Property_Area = factor(Property_Area),
  Loan_Status = factor(ifelse(Loan_Status == "Y", TRUE, FALSE))
)

# Feature Engineering
rawData <- rawData %>%
  mutate(Total_Income = ApplicantIncome + CoapplicantIncome,
         Income_to_Loan = Total_Income / LoanAmount)

# Drop all missing values just for testing TODO
rawData <- na.omit(rawData)

# Check for null values and handle them (if any)
null_counts <- colSums(is.na(rawData))
print(null_counts)

# Save the data as a csv #TODO
write.csv(rawData, "C:/Users/timst/Documents/GitHub/E-Business-Loan-Status-Prediction/rawData.csv")
```

------------------------------------------------------------------------

# Initial Data sighting

```{r}
# Plot 1: Distribution of Loan Status with customized colors
ggplot(rawData, aes(x = Loan_Status, fill = Loan_Status)) +
  geom_bar(color = "black") +
  scale_fill_manual(values = c("TRUE" = "#90EE90", "FALSE" = "#FFB6C1")) +
  theme_minimal() +
  ggtitle("Distribution of Loan Status")
```

```{r}
# Plot 2: Distribution of Gender with customized RGB colors
ggplot(rawData, aes(x = Gender, fill = Gender)) +
  geom_bar(color = "black") +
  scale_fill_manual(values = c("Male" = "#89CFF0", "Female" = "#FFB6C1")) +
  theme_minimal() +
  ggtitle("Distribution of Gender")
```

```{r}
# Plot 3: Average Loan Amount by Property Area
avg_loan_amount <- rawData %>%
  group_by(Property_Area) %>%
  summarise(Average_LoanAmount = mean(LoanAmount, na.rm = TRUE))

ggplot(avg_loan_amount, aes(x = Property_Area, y = Average_LoanAmount, fill = Property_Area)) +
  geom_bar(stat = "identity", color = "black") +
  theme_minimal() +
  ggtitle("Average Loan Amount by Property Area") +
  labs(y = "Average Loan Amount", fill = "Property Area")
```

```{r}
# Plot 4: Distribution of Loan Status by Education
ggplot(rawData, aes(x = Loan_Status, fill = Education)) +
  geom_bar(position = "dodge", color = "black") +
  theme_minimal() +
  ggtitle("Distribution of Loan Status by Education") +
  labs(fill = "Education")
```

```{r}
# Plot 5: Distribution of Loan Status by Self Employed status
ggplot(rawData, aes(x = Loan_Status, fill = Self_Employed)) +
  geom_bar(position = "dodge", color = "black") +
  theme_minimal() +
  ggtitle("Distribution of Loan Status by Self Employed Status") +
  labs(fill = "Self Employed")
```

# Split Data into Training and Testing Sets

```{r}
set.seed(123)  # For reproducibility

# Split the data into training (80%) and testing (20%) sets
trainIndex <- createDataPartition(rawData$Loan_Status, p = .8, 
                                  list = FALSE, 
                                  times = 1)
trainData <- rawData[ trainIndex,]
testData  <- rawData[-trainIndex,]
```

# Scale the Data

```{r}
# Identify numeric columns
numeric_cols <- sapply(trainData, is.numeric)

# Apply scaling and centering to numeric columns
preProc <- preProcess(trainData[, numeric_cols], method = c("center", "scale"))
trainData[, numeric_cols] <- predict(preProc, trainData[, numeric_cols])
testData[, numeric_cols] <- predict(preProc, testData[, numeric_cols])

print(head(trainData))
print(head(testData))

```

# Train and Evaluate the Random Forest Model

```{r}
# Random Forest hyperparameter tuning
rf_grid <- expand.grid(mtry = c(2, 4, 6))  # Only include mtry in the grid
train_control <- trainControl(method = "cv", number = 10)
rf_model <- train(Loan_Status ~ ., data = trainData, method = "rf", tuneGrid = rf_grid, trControl = train_control, ntree = 500)  # Specify ntree separately

# Predict on the test data
rf_predictions <- predict(rf_model, newdata = testData)

# Confusion matrix
rf_conf_matrix <- confusionMatrix(rf_predictions, testData$Loan_Status)
print(rf_conf_matrix)

# Plot ROC curve and calculate AUC
rf_roc_obj <- roc(testData$Loan_Status, as.numeric(rf_predictions))
rf_auc <- auc(rf_roc_obj)
plot(rf_roc_obj, main="ROC Curve for Random Forest Model")

rf_metrics <- list(Accuracy = rf_conf_matrix$overall['Accuracy'], AUC = rf_auc)
print(rf_metrics)

```

# Train and Evaluate the KNN Model

```{r}
# Load necessary library
library(caret)

# Identify categorical columns
categorical_cols <- sapply(trainData, is.factor)

# Apply one-hot encoding to categorical columns
dummies <- dummyVars(~ ., data = trainData[, categorical_cols])
train_categorical <- predict(dummies, newdata = trainData[, categorical_cols])
test_categorical <- predict(dummies, newdata = testData[, categorical_cols])

# Combine numeric and encoded categorical features
train_knn <- cbind(trainData[, numeric_cols], train_categorical)
test_knn <- cbind(testData[, numeric_cols], test_categorical)

# Train the KNN model (k = 5)
knn_predictions <- knn(train = train_knn, test = test_knn, cl = trainData$Loan_Status, k = 5)

# Confusion matrix
knn_conf_matrix <- confusionMatrix(knn_predictions, testData$Loan_Status)
print(knn_conf_matrix)

# Plot ROC curve and calculate AUC
knn_roc_obj <- roc(testData$Loan_Status, as.numeric(knn_predictions))
knn_auc <- auc(knn_roc_obj)
plot(knn_roc_obj, main="ROC Curve for KNN Model")

knn_metrics <- list(Accuracy = knn_conf_matrix$overall['Accuracy'], AUC = knn_auc)
print(knn_metrics)

```

# Train and Evaluate the Decision Tree Model

```{r}
# Train the decision tree model
dt_model <- rpart(Loan_Status ~ ., data = trainData, method = "class")

# Predict on the test data
dt_predictions <- predict(dt_model, newdata = testData, type = "class")

# Confusion matrix
dt_conf_matrix <- confusionMatrix(dt_predictions, testData$Loan_Status)
print(dt_conf_matrix)

# Plot ROC curve and calculate AUC
dt_roc_obj <- roc(testData$Loan_Status, as.numeric(dt_predictions))
dt_auc <- auc(dt_roc_obj)
plot(dt_roc_obj, main="ROC Curve for Decision Tree Model")

dt_metrics <- list(Accuracy = dt_conf_matrix$overall['Accuracy'], AUC = dt_auc)
print(dt_metrics)

```

# Compare Models

```{r}
# Combine metrics into a data frame
model_comparison <- data.frame(
  Model = c("Random Forest", "KNN", "Decision Tree"),
  Accuracy = c(rf_metrics$Accuracy, knn_metrics$Accuracy, dt_metrics$Accuracy),
  AUC = c(rf_metrics$AUC, knn_metrics$AUC, dt_metrics$AUC)
)

print(model_comparison)

# Identify the best model
best_model_name <- model_comparison$Model[which.max(model_comparison$AUC)]
cat("Best model based on AUC is:", best_model_name, "\n")

best_model <- switch(best_model_name,
                     "Random Forest" = rf_model,
                     "KNN" = knn_predictions,
                     "Decision Tree" = dt_model)

# Perform further analysis with the best model (if applicable)
if (best_model_name == "Random Forest") {
  # Plot the importance of variables
  varImpPlot(best_model, main="Variable Importance in Random Forest Model")
} else if (best_model_name == "Decision Tree") {
  # Plot the decision tree
  rpart.plot(best_model, main="Decision Tree for Loan Status Prediction")
}

```
